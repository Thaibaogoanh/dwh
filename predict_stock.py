import pandas as pd
import numpy as np
import pandas_ta as ta
from sqlalchemy import create_engine
from tensorflow.keras.models import load_model
import joblib
import warnings

warnings.filterwarnings("ignore")

# ==============================================================================
# 1. INPUT C·ª¶A B·∫†N (C√ì TH√äM M√É C·ªî PHI·∫æU)
# ==============================================================================
INPUT_TICKER = 'VPB'      # <--- Input Ticker Code
INPUT_OPEN   = 27600.0
INPUT_HIGH   = 28200.0
INPUT_LOW    = 27600.0
INPUT_CLOSE  = 27800.0
INPUT_VOLUME = 11788681.0

print(f"--- ƒêang d·ª± b√°o cho {INPUT_TICKER} (Global Model) ---")

# ==============================================================================
# 2. LOAD CHECKPOINTS
# ==============================================================================
try:
    model = load_model('global_lstm_model.keras')
    scalers_dict = joblib.load('scalers_dict.pkl')
    ticker_binarizer = joblib.load('ticker_binarizer.pkl')
    print("-> ƒê√£ load Model, Scalers v√† Binarizer.")
except:
    print("L·ªói: Thi·∫øu file checkpoint. H√£y ch·∫°y train_global_model.py tr∆∞·ªõc.")
    exit()

# Ki·ªÉm tra xem m√£ n√†y c√≥ trong t·∫≠p train kh√¥ng
if INPUT_TICKER not in scalers_dict:
    print(f"L·ªói: Model ch∆∞a t·ª´ng h·ªçc m√£ {INPUT_TICKER} n√†y (Ch∆∞a c√≥ Scaler).")
    exit()

scaler = scalers_dict[INPUT_TICKER] # L·∫•y scaler ri√™ng c·ªßa VCB

# ==============================================================================
# 3. K·∫æT N·ªêI DB & L·∫§Y L·ªäCH S·ª¨
# ==============================================================================
DB_USER = 'postgres.llthiavkzkvklakkapgz'
DB_PASSWORD = 'bao19012004.'
DB_HOST = 'aws-1-ap-south-1.pooler.supabase.com'
DB_PORT = '5432'
DB_NAME = 'postgres'
connection_str = f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'
engine = create_engine(connection_str)

query = f"""
SELECT f1.close_price, f1.open_price, f1.high_price, f1.low_price, f1.volume
FROM data_warehouse.fact_daily_trading f1
JOIN data_warehouse.dim_ticker t ON f1.ticker_key = t.ticker_key
JOIN data_warehouse.dim_date d ON f1.date_key = d.date_key
WHERE t.ticker_code = '{INPUT_TICKER}'
ORDER BY d.full_date DESC LIMIT 200
"""
df_history = pd.read_sql(query, engine)
df_history = df_history.iloc[::-1].reset_index(drop=True)

# √âp ki·ªÉu float
for c in ['close_price', 'open_price', 'high_price', 'low_price', 'volume']:
    df_history[c] = df_history[c].astype(float)

# ==============================================================================
# 4. GH√âP & T√çNH TO√ÅN CH·ªà S·ªê
# ==============================================================================
new_row = pd.DataFrame([{
    'close_price': float(INPUT_CLOSE), 'open_price': float(INPUT_OPEN),
    'high_price': float(INPUT_HIGH), 'low_price': float(INPUT_LOW),
    'volume': float(INPUT_VOLUME)
}])
df_full = pd.concat([df_history, new_row], ignore_index=True)

# T√≠nh to√°n indicators (Logic y h·ªát file train)
df_full['ma_10'] = ta.sma(df_full['close_price'], length=10)
df_full['ma_30'] = ta.sma(df_full['close_price'], length=30)
df_full['rsi'] = ta.rsi(df_full['close_price'], length=14)
macd = ta.macd(df_full['close_price'])
df_full['macd'] = macd.iloc[:, 0] if macd is not None else 0
bbands = ta.bbands(df_full['close_price'], length=20, std=2)
if bbands is not None:
    df_full['bollinger_upper'] = bbands.iloc[:, 2]
    df_full['bollinger_lower'] = bbands.iloc[:, 0]
else:
    df_full['bollinger_upper'] = 0; df_full['bollinger_lower'] = 0

df_full = df_full.fillna(method='ffill').fillna(0)

# ==============================================================================
# 5. CHU·∫®N B·ªä INPUT VECTOR (Numeric + One-Hot)
# ==============================================================================
LOOK_BACK = 60
df_input = df_full.tail(LOOK_BACK)

feature_cols = ['close_price', 'open_price', 'high_price', 'low_price', 'volume', 
                'ma_10', 'ma_30', 'rsi', 'macd', 'bollinger_upper', 'bollinger_lower']

# A. Scale d·ªØ li·ªáu s·ªë (b·∫±ng scaler ri√™ng c·ªßa VCB)
numeric_values = df_input[feature_cols].values
input_scaled_numeric = scaler.transform(numeric_values) # (60, 11)

# B. T·∫°o One-Hot Vector cho Ticker
# ticker_binarizer.transform tr·∫£ v·ªÅ m·∫£ng (1, s·ªë_l∆∞·ª£ng_m√£). 
# Ta c·∫ßn nh√¢n b·∫£n n√≥ l√™n 60 l·∫ßn ƒë·ªÉ kh·ªõp v·ªõi chu·ªói th·ªùi gian (60, s·ªë_l∆∞·ª£ng_m√£)
ticker_vec_1row = ticker_binarizer.transform([INPUT_TICKER]) # V√≠ d·ª•: [[0, 1, 0...]]
ticker_vec_60rows = np.repeat(ticker_vec_1row, LOOK_BACK, axis=0) # L·∫∑p l·∫°i 60 l·∫ßn

# C. Gh√©p l·∫°i
# K·∫øt qu·∫£ l√† m·∫£ng (60, 11 + s·ªë_l∆∞·ª£ng_m√£)
final_input = np.hstack([input_scaled_numeric, ticker_vec_60rows])

# Reshape cho LSTM (1, 60, features)
input_reshaped = np.array([final_input])

# ==============================================================================
# 6. D·ª∞ ƒêO√ÅN
# ==============================================================================
print("-> ƒêang ch·∫°y Model...")
predicted_scaled = model.predict(input_reshaped, verbose=0)

# Inverse Transform
# T·∫°o ma tr·∫≠n gi·∫£ kh·ªõp v·ªõi s·ªë c·ªôt numeric (11 c·ªôt) ƒë·ªÉ inverse
pred_matrix = np.zeros((1, len(feature_cols)))
pred_matrix[0, 0] = predicted_scaled[0, 0]
final_price = scaler.inverse_transform(pred_matrix)[0, 0]

print(f"\n===========================================")
print(f"Input: {INPUT_TICKER} - Close: {INPUT_CLOSE:,.0f}")
print(f"üëâ D·ª∞ B√ÅO: {final_price:,.0f} VND")
print(f"===========================================")